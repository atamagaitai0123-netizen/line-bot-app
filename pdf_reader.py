# pdf_reader.py
# æˆç¸¾PDFã‹ã‚‰å˜ä½å–å¾—çŠ¶æ³ã‚’è§£æã—ã¦å’æ¥­è¦ä»¶ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# å¿…è¦: pip install pdfplumber
# ä½¿ã„æ–¹:
#   text = check_pdf("æˆç¸¾.pdf")                  # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™
#   text, lack = check_pdf("æˆç¸¾.pdf", return_dict=True)  # ãƒ†ã‚­ã‚¹ãƒˆã¨ä¸è¶³è¾æ›¸ã‚’è¿”ã™

from pathlib import Path
import re
from typing import Dict, Any, Tuple, List, Optional

try:
    import pdfplumber
except Exception as e:
    raise ImportError("pdfplumber ãŒå¿…è¦ã§ã™ã€‚`pip install pdfplumber` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚") from e

# -------------------------
# è¦ä»¶ï¼ˆå¿…è¦å˜ä½ï¼‰ - å¿…è¦ã«å¿œã˜ã¦ç·¨é›†
# -------------------------
GRAD_REQUIREMENTS = {
    "å­¦éƒ¨å¿…ä¿®ç§‘ç›®åŒºåˆ†": 12,
    "æ•™é¤Šç§‘ç›®åŒºåˆ†": 24,
    "å¤–å›½èªç§‘ç›®åŒºåˆ†": 16,
    "ä½“è‚²å®ŸæŠ€ç§‘ç›®åŒºåˆ†": 2,
    "çµŒå–¶å­¦ç§‘åŸºç¤å°‚é–€ç§‘ç›®": 14,
    "çµŒå–¶å­¦ç§‘å°‚é–€ç§‘ç›®": 32,
    "è‡ªç”±å±¥ä¿®ç§‘ç›®": 24,
    "åˆè¨ˆ": 124,
}

# å‚™è€ƒã§ç¢ºèªã™ã‚‹å¿…ä¿®ã®å†…è¨³
SUB_REQUIREMENTS = {
    "è‹±èªï¼ˆåˆç´šï¼‰": 4,
    "åˆç¿’å¤–å›½èª": 8,
    "å¤–å›½èªã‚’ç”¨ã„ãŸç§‘ç›®": 4,
}

# è‡ªç”±å±¥ä¿®ã«å«ã‚ã‚‹å‡ºæ‰€ã‚«ãƒ†ã‚´ãƒªï¼ˆè¡¨è¨˜æºã‚Œã‚’è€ƒæ…®ã—ãŸæ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã§æ¢ã™ï¼‰
FREE_ELECTIVE_PATTERNS = [
    r"å®Ÿç¿’é–¢é€£ç§‘ç›®",
    r"ICTãƒªãƒ†ãƒ©ã‚·ãƒ¼ç§‘ç›®",
    r"æ¼”ç¿’ç§‘ç›®\(æ¼”ç¿’I\)",
    r"æ¼”ç¿’ç§‘ç›®\(æ¼”ç¿’IIA~IIIB\)",
    r"æ¼”ç¿’ç§‘ç›®",  # ç·©ãæ‹¾ã†
    r"å…¨å­¦å…±é€šç·åˆè¬›åº§",
    r"å›½éš›æ•™è‚²ãƒ—ãƒ­ã‚°ãƒ©ãƒ ç§‘ç›®",
    r"ã‚°ãƒ­ãƒ¼ãƒãƒ«äººæè‚²æˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ç§‘ç›®",
    r"ä»–å­¦éƒ¨ç§‘ç›®",
]

# å¹´åº¦ã¨æ€ã‚ã‚Œã‚‹æ•°å€¤ã®é–¾å€¤ï¼ˆ>=2000 ã‚’å¹´åº¦ã¨ã—ã¦é™¤å¤–ï¼‰
YEAR_THRESHOLD = 2000
# å˜ä½ã¨ã—ã¦ç¾å®Ÿçš„ã«è¨±å®¹ã™ã‚‹ç¯„å›²ï¼ˆä¾‹: 0ã€œ30 å˜ä½ï¼‰
MIN_CREDIT = 0
MAX_CREDIT = 30

YEARS_ORDER = ['25', '24', '23', '22']


# -------------------------
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# -------------------------
def normalize(s: Optional[str]) -> str:
    if s is None:
        return ""
    return re.sub(r'\s+', '', str(s))


def extract_lines_from_page(page, line_tol: int = 6) -> List[Dict[str, Any]]:
    """
    pdfplumber ã® extract_words ã‚’åˆ©ç”¨ã—ã¦è«–ç†è¡Œã«ã¾ã¨ã‚ã‚‹ã€‚
    æˆ»ã‚Šå€¤: [{'text': ..., 'first_x': x0, 'top': top, 'words': [...], 'nums': [...]}]
    """
    words = page.extract_words()
    if not words:
        return []
    words_sorted = sorted(words, key=lambda w: (w['top'], w['x0']))
    lines = []
    cur_top = words_sorted[0]['top']
    cur_words = []
    for w in words_sorted:
        if abs(w['top'] - cur_top) <= line_tol:
            cur_words.append(w)
        else:
            cur_words_sorted = sorted(cur_words, key=lambda x: x['x0'])
            text = " ".join(wd['text'] for wd in cur_words_sorted)
            nums = re.findall(r'\d+', text)
            lines.append({'text': text, 'first_x': cur_words_sorted[0]['x0'],
                          'top': cur_top, 'nums': nums, 'words': cur_words_sorted})
            cur_top = w['top']
            cur_words = [w]
    if cur_words:
        cur_words_sorted = sorted(cur_words, key=lambda x: x['x0'])
        text = " ".join(wd['text'] for wd in cur_words_sorted)
        nums = re.findall(r'\d+', text)
        lines.append({'text': text, 'first_x': cur_words_sorted[0]['x0'],
                      'top': cur_top, 'nums': nums, 'words': cur_words_sorted})
    return lines


def _filter_unit_numbers(nums: List[str]) -> List[int]:
    """
    æŠ½å‡ºã—ãŸæ•°å­—ãƒªã‚¹ãƒˆã‹ã‚‰ã€Œå˜ä½ã¨ã—ã¦æ„å‘³ã‚’æŒã¤æ•°å€¤ã€ã‚’è¿”ã™ã€‚
    - å¹´åº¦ï¼ˆ>= YEAR_THRESHOLDï¼‰ã¯é™¤å¤–
    - ç¯„å›²å¤–ã®æ•°ï¼ˆ> MAX_CREDITç­‰ï¼‰ã¯é™¤å¤–
    """
    out = []
    for s in nums:
        try:
            v = int(s)
        except Exception:
            continue
        if v >= YEAR_THRESHOLD:
            continue
        if v < MIN_CREDIT or v > MAX_CREDIT:
            continue
        out.append(v)
    return out


def extract_credit_by_label(text: str) -> Optional[int]:
    """
    ã¾ãšã€Œ(\d+)å˜ä½ã€ã¨ã„ã†å½¢å¼ã‚’æ¢ã™ï¼ˆã“ã‚Œã‚’æœ€å„ªå…ˆï¼‰ã€‚
    ç„¡ã‘ã‚Œã°è¡Œã®ä¸­ã®é©åˆ‡ãªå°ã•ã„æ•°å€¤ã‚’è¿”ã™ï¼ˆ_filter_unit_numberså‚ç…§ï¼‰ã€‚
    æˆ»ã‚Šå€¤ã¯å˜ä½æ•°ï¼ˆintï¼‰ã‹ Noneã€‚
    """
    # å„ªå…ˆ: ã€Œæ•°å­— + å˜ä½ã€
    m = re.findall(r'(\d+)\s*å˜ä½', text)
    if m:
        # è¤‡æ•°è¦‹ã¤ã‹ã‚‹å ´åˆã¯æœ€å¾Œã®ã‚‚ã®ï¼ˆåˆè¨ˆã‚„å³ç«¯ã®åˆè¨ˆã‚’æƒ³å®šï¼‰ã‚’ä½¿ã†
        vals = [int(x) for x in m if int(x) < YEAR_THRESHOLD and MIN_CREDIT <= int(x) <= MAX_CREDIT]
        if vals:
            return vals[-1]
    # æ¬¡ã«ã€è¡Œå†…ã®å°ã•ã„æ•°å€¤ï¼ˆå¹´åº¦é™¤å¤–ï¼‰ã‚’æ¢ã™
    filtered = _filter_unit_numbers(re.findall(r'\d+', text))
    if filtered:
        return filtered[-1]
    return None


def find_keyword_rows(lines: List[Dict[str, Any]], keywords: List[str]) -> List[Dict[str, Any]]:
    """
    lines ã®ä¸­ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆå®Œå…¨ä¸€è‡´ã¾ãŸã¯éƒ¨åˆ†ä¸€è‡´ï¼‰ã‚’å«ã‚€è¡Œã‚’æŠ½å‡ºã€‚
    keywords ã¯è¡¨è¨˜ãã®ã¾ã¾ã®ãƒªã‚¹ãƒˆã€‚æˆ»ã‚Šå€¤ã¯è¡Œã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã« 'credit' ã‚’è¿½åŠ ã€‚
    """
    res = []
    for ln in lines:
        txt = ln['text']
        for kw in keywords:
            if normalize(kw) in normalize(txt):
                credit = extract_credit_by_label(txt)
                r = dict(ln)
                r['credit'] = credit
                res.append(r)
                break
    # é‡è¤‡ï¼ˆtop, first_x, textï¼‰ã‚’å‰Šé™¤
    uniq = []
    seen = set()
    for r in res:
        key = (r['top'], r['first_x'], r['text'])
        if key not in seen:
            seen.add(key)
            uniq.append(r)
    return uniq


# -------------------------
# ãƒ¡ã‚¤ãƒ³: check_pdf
# -------------------------
def check_pdf(pdf_path: str, page_no: int = 0, return_dict: bool = False) -> Any:
    """
    pdf_path: PDFãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    page_no: è§£æã™ã‚‹ãƒšãƒ¼ã‚¸ç•ªå·ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ0ï¼‰
    return_dict: True ã®å ´åˆã€(formatted_text, lack_dict) ã‚’è¿”ã™
    """
    p = Path(pdf_path)
    if not p.exists():
        raise FileNotFoundError(pdf_path)

    # open and extract logical lines from the target page
    with pdfplumber.open(pdf_path) as pdf:
        if page_no < 0 or page_no >= len(pdf.pages):
            page = pdf.pages[-1]
        else:
            page = pdf.pages[page_no]
        lines = extract_lines_from_page(page, line_tol=6)

    # æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç¾¤ï¼ˆä¸»è¦ã‚«ãƒ†ã‚´ãƒª + å‚™è€ƒ + è‡ªç”±å±¥ä¿®ã‚½ãƒ¼ã‚¹ï¼‰
    keywords = list(GRAD_REQUIREMENTS.keys()) + list(SUB_REQUIREMENTS.keys())
    keywords += [re.sub(r'\\', '', pat) for pat in FREE_ELECTIVE_PATTERNS]
    keywords += ["åˆè¨ˆ", "ç·åˆè¨ˆ"]

    logical_rows = find_keyword_rows(lines, keywords)

    # main_selected: å„ã‚«ãƒ†ã‚´ãƒªã«å¯¾ã—ã¦æœ€è‰¯ã¨æ€ã‚ã‚Œã‚‹è¡Œï¼ˆæœ«å°¾ã®å˜ä½ãŒæœ€å¤§ã®ã‚‚ã®ï¼‰ã‚’é¸ã¶
    main_selected: Dict[str, Optional[Dict[str, Any]]] = {}
    for key in GRAD_REQUIREMENTS.keys():
        cand = [r for r in logical_rows if normalize(key) in normalize(r['text'])]
        best = None
        best_val = -1
        for c in cand:
            val = c.get('credit')
            if val is None:
                # fallback: è¡Œå†…æ•°å€¤ãƒ•ã‚£ãƒ«ã‚¿ã§æœ€å¾Œã®å°ã•ã„æ•°ã‚’ä½¿ã†ï¼ˆparseæ™‚ã¨åŒæ§˜ï¼‰
                val = extract_credit_by_label(c['text'])
            if val is None:
                continue
            if val > best_val:
                best_val = val
                best = {'metrics': {'åˆè¨ˆ': val}, 'row': c}
        main_selected[key] = best

    # subs: å‚™è€ƒå†…ã®å¿…ä¿®ï¼ˆè‹±èªï¼ˆåˆç´šï¼‰ç­‰ï¼‰ã¯å˜ç‹¬ã§æ¢ã™ã€‚å˜ä½ãƒ©ãƒ™ãƒ«ãŒã‚ã‚‹è¡Œã‚’å„ªå…ˆã€‚
    sub_results: Dict[str, Dict[str, Any]] = {}
    for sub, req in SUB_REQUIREMENTS.items():
        cand = [r for r in logical_rows if normalize(sub) in normalize(r['text'])]
        if not cand:
            # è©²å½“è¡ŒãŒãªã‘ã‚Œã°0
            sub_results[sub] = {'req': req, 'got': 0, 'row': None}
            continue
        # å„ªå…ˆ: å˜ä½ãƒ©ãƒ™ãƒ«ãŒã‚ã‚‹ã‚‚ã® -> æŠœãå‡ºã—å€¤ãŒæ­£ã—ã„ã‚‚ã®ã‚’é¸ã¶
        best_val = None
        best_row = None
        for c in cand:
            val = c.get('credit')
            if val is None:
                val = extract_credit_by_label(c['text'])
            # ignore unrealistic values
            if val is None:
                continue
            if best_val is None or val > best_val:
                best_val = val
                best_row = c
        sub_results[sub] = {'req': req, 'got': int(best_val or 0), 'row': best_row}

    # parsed: å„ã‚«ãƒ†ã‚´ãƒªã®å–å¾—å˜ä½ï¼ˆå­˜åœ¨ã—ãªã„ã‚«ãƒ†ã‚´ãƒªã¯0ï¼‰
    parsed: Dict[str, int] = {}
    for key in GRAD_REQUIREMENTS.keys():
        sel = main_selected.get(key)
        got = int(sel['metrics']['åˆè¨ˆ']) if (sel and sel.get('metrics') and sel['metrics'].get('åˆè¨ˆ') is not None) else 0
        parsed[key] = got
    # subçµæœã§ä¸Šæ›¸ãï¼ˆå‚™è€ƒæ¬„ã®æ•°å€¤ã‚’å„ªå…ˆï¼‰
    for sub, info in sub_results.items():
        parsed[sub] = int(info['got'] or 0)

    # --- è‡ªç”±å±¥ä¿®ã®åˆç®—: FREE_ELECTIVE_PATTERNS ã‹ã‚‰è¡Œã‚’æ¢ã—ã¦åˆè¨ˆã™ã‚‹ ---
    free_sum = 0
    # 1) ã¾ãšã€æˆç¸¾è¡¨ã«ç›´æ¥ã€Œè‡ªç”±å±¥ä¿®ç§‘ç›®ã€ãŒè¼‰ã£ã¦ã„ã¦å€¤ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ã†ï¼ˆå„ªå…ˆï¼‰
    direct_free = parsed.get("è‡ªç”±å±¥ä¿®ç§‘ç›®", 0)
    if direct_free and direct_free > 0:
        parsed["è‡ªç”±å±¥ä¿®ç§‘ç›®"] = int(direct_free)
    else:
        # 2) å‡ºæ‰€ã‚«ãƒ†ã‚´ãƒªç¾¤ã‹ã‚‰åˆç®—ï¼ˆlogical_rows ã¨ lines ã‹ã‚‰æ¢ã™ï¼‰
        # logical_rows ã«æ—¢ã«å«ã¾ã‚Œã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        for pat in FREE_ELECTIVE_PATTERNS:
            for r in logical_rows:
                if re.search(pat, r['text']):
                    v = r.get('credit')
                    if v is None:
                        v = extract_credit_by_label(r['text'])
                    if v is not None:
                        free_sum += int(v)
        # 3) ã•ã‚‰ã« linesï¼ˆç”Ÿã®è¡Œåˆ—ï¼‰ã‚’èµ°æŸ»ã—ã¦è©²å½“ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¡Œæœ«æ•°å­—ã‚’æ‹¾ã†ï¼ˆé‡è¤‡ã«æ³¨æ„ï¼‰
        #    ï¼ˆlogical_rows ã§æ‹¾ãˆãªã„è¡¨è¨˜æºã‚Œã«å‚™ãˆã‚‹ï¼‰
        seen_texts = set(r['text'] for r in logical_rows)
        for ln in lines:
            txt = ln['text']
            if txt in seen_texts:
                continue
            for pat in FREE_ELECTIVE_PATTERNS:
                if re.search(pat, txt):
                    v = extract_credit_by_label(txt)
                    if v is not None:
                        free_sum += int(v)
                    break
        parsed["è‡ªç”±å±¥ä¿®ç§‘ç›®"] = int(free_sum or 0)

    # åˆè¨ˆã®å–å¾—ï¼ˆparsed ä¸­åˆè¨ˆãŒ0ã®å ´åˆã€åˆè¨ˆè¡Œã‚’æ¢ã™ï¼‰
    total_got = int(parsed.get("åˆè¨ˆ", 0) or 0)
    if total_got == 0:
        # logical_rows ã«åˆè¨ˆè¡ŒãŒã‚ã‚‹ã‹
        for r in logical_rows:
            if "åˆè¨ˆ" in r['text'] or "ç·åˆè¨ˆ" in r['text']:
                v = r.get('credit')
                if v is None:
                    v = extract_credit_by_label(r['text'])
                if v is not None:
                    total_got = int(v)
                    break
    # fallback: parsed ã®å…¨ã‚«ãƒ†ã‚´ãƒªå’Œï¼ˆé™¤å¤–ã—ãªã„ã¨äºŒé‡è¨ˆä¸Šã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§æ³¨æ„ï¼‰
    if total_got == 0:
        # åˆè¨ˆã¯ä¸»è¦ã‚«ãƒ†ã‚´ãƒªï¼ˆåˆè¨ˆã‚­ãƒ¼ã¯é™¤ãï¼‰ã‚’åˆç®—ã—ã¦ç®—å‡ºï¼ˆè‡ªç”±å±¥ä¿®ã¯ parsed ã«åæ˜ æ¸ˆï¼‰
        total_got = sum(parsed[k] for k in parsed.keys() if k != "åˆè¨ˆ")

    # -------------------------
    # ä¸è¶³è¨ˆç®—
    # -------------------------
    lack_dict: Dict[str, int] = {}
    known_short_sum = 0

    # main categoriesï¼ˆè‡ªç”±å±¥ä¿®ã¨åˆè¨ˆã¯å¾Œå›ã—ï¼‰
    for key, req in GRAD_REQUIREMENTS.items():
        if key in ("åˆè¨ˆ", "è‡ªç”±å±¥ä¿®ç§‘ç›®"):
            continue
        got = int(parsed.get(key, 0) or 0)
        if got < req:
            lack = req - got
            lack_dict[key] = lack
            known_short_sum += lack

    # subs (å‚™è€ƒå†…å¿…ä¿®)
    for sub, req in SUB_REQUIREMENTS.items():
        got = int(parsed.get(sub, 0) or 0)
        if got < req:
            lack = req - got
            lack_dict[sub] = lack
            known_short_sum += lack

    # åˆè¨ˆã®ä¸è¶³
    total_req = GRAD_REQUIREMENTS.get("åˆè¨ˆ", 0)
    total_missing = max(0, total_req - (int(total_got or 0)))
    lack_dict["åˆè¨ˆ"] = total_missing

    # è‡ªç”±å±¥ä¿®ã®ä¸è¶³ã‚’æ¨å®š: åˆè¨ˆä¸è¶³ - æ—¢çŸ¥ä¸è¶³
    free_missing_est = total_missing - known_short_sum
    if free_missing_est < 0:
        free_missing_est = 0
    # ãŸã ã—è‡ªç”±å±¥ä¿®ã®æ‰€è¦ï¼ˆGRAD_REQUIREMENTSï¼‰ã¨å–å¾—(parsed)ã¨ã®å·®ã‚‚è€ƒæ…®
    free_have = int(parsed.get("è‡ªç”±å±¥ä¿®ç§‘ç›®", 0) or 0)
    free_need = GRAD_REQUIREMENTS.get("è‡ªç”±å±¥ä¿®ç§‘ç›®", 0)
    deduced_free_missing = max(0, free_need - free_have)
    # æœ€çµ‚çš„ã«è¡¨ç¤ºã™ã‚‹è‡ªç”±å±¥ä¿®ä¸è¶³ã¯ã€æ¨å®šå€¤ã¨å¿…ä¿®å·®åˆ†ã®æœ€å¤§å€¤
    chosen_free_missing = max(free_missing_est, deduced_free_missing)
    if chosen_free_missing > 0:
        lack_dict["è‡ªç”±å±¥ä¿®ç§‘ç›®"] = int(chosen_free_missing)

    # -------------------------
    # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
    # -------------------------
    out_lines: List[str] = []
    out_lines.append("æˆç¸¾è¡¨ã‚’è§£æã—ã¾ã—ãŸï¼\n")
    out_lines.append("=== å„ã‚«ãƒ†ã‚´ãƒªãƒã‚§ãƒƒã‚¯ ===")
    for key, req in GRAD_REQUIREMENTS.items():
        if key == "åˆè¨ˆ":
            continue
        got = parsed.get(key, 0)
        got_display = "â€•" if got is None else str(got)
        if got is None:
            status = "âŒ ãƒ‡ãƒ¼ã‚¿ãªã—"
        else:
            if got < req:
                status = f"âŒ ä¸è¶³ {req - got}"
            else:
                if key == "å¤–å›½èªç§‘ç›®åŒºåˆ†":
                    # å‚™è€ƒå†…ã®å¿…ä¿®ãŒæº€ãŸã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
                    sub_ng = False
                    for subk in ("è‹±èªï¼ˆåˆç´šï¼‰", "åˆç¿’å¤–å›½èª"):
                        if int(parsed.get(subk, 0) or 0) < SUB_REQUIREMENTS.get(subk, 0):
                            sub_ng = True
                    status = "ğŸ”º å‚™è€ƒä¸è¶³ã‚ã‚Š" if sub_ng else "âœ…"
                else:
                    status = "âœ…"
        out_lines.append(f"ãƒ»{key:<20} å¿…è¦={req:<3}  å–å¾—={got_display:<3}  {status}")

    # åˆè¨ˆè¡Œ
    total_status = (f"âŒ ä¸è¶³ {total_req - total_got}" if total_got < total_req else "âœ…")
    out_lines.append(f"\nåˆè¨ˆ{'':<15} å¿…è¦={total_req:<3}  å–å¾—={str(total_got):<3}  {total_status}")

    # å‚™è€ƒï¼ˆå¿…ä¿®ç§‘ç›®ï¼‰
    out_lines.append("\n=== å‚™è€ƒï¼ˆå¿…ä¿®ç§‘ç›®ï¼‰ ===")
    for sub, need in SUB_REQUIREMENTS.items():
        got = int(parsed.get(sub, 0) or 0)
        st = "âœ…" if got >= need else f"âŒ ä¸è¶³ {need - got}"
        out_lines.append(f"{sub:<15} å¿…è¦={need:<3}  å–å¾—={got:<3}  {st}")

    # ä¸è¶³ä¸€è¦§ï¼ˆè©³ç´°ï¼‰
    out_lines.append("\n=== ä¸è¶³ã—ã¦ã„ã‚‹ç§‘ç›®åŒºåˆ† ===")
    # main æ¬ è½ï¼ˆè‡ªç”±å±¥ä¿®ã¯åˆ¥é€”ï¼‰
    for k in GRAD_REQUIREMENTS.keys():
        if k in ("åˆè¨ˆ", "è‡ªç”±å±¥ä¿®ç§‘ç›®"):
            continue
        if k in lack_dict:
            out_lines.append(f"ãƒ»{k}: ã‚ã¨ {lack_dict[k]} å˜ä½")
    # sub æ¬ è½
    for subk in SUB_REQUIREMENTS.keys():
        if subk in lack_dict:
            out_lines.append(f"ãƒ»{subk}: ã‚ã¨ {lack_dict[subk]} å˜ä½")
    # è‡ªç”±å±¥ä¿®ï¼ˆæ¨å®šï¼‰ãŒã‚ã‚Œã°è¡¨ç¤º
    if "è‡ªç”±å±¥ä¿®ç§‘ç›®" in lack_dict:
        out_lines.append(f"ãƒ»è‡ªç”±å±¥ä¿®ç§‘ç›®: ã‚ã¨ {lack_dict['è‡ªç”±å±¥ä¿®ç§‘ç›®']} å˜ä½")
    out_lines.append(f"ãƒ»åˆè¨ˆ: ã‚ã¨ {lack_dict.get('åˆè¨ˆ', 0)} å˜ä½")

    # ç·åˆåˆ¤å®š
    ok_main = all(int(parsed.get(k, 0) or 0) >= v for k, v in GRAD_REQUIREMENTS.items() if k != "åˆè¨ˆ")
    ok_subs = all(int(parsed.get(k, 0) or 0) >= v for k, v in SUB_REQUIREMENTS.items())
    if ok_main and ok_subs and int(total_got or 0) >= total_req:
        out_lines.append("\nğŸ‰ å’æ¥­è¦ä»¶ã‚’æº€ãŸã—ã¦ã„ã¾ã™")
    else:
        out_lines.append("\nâŒ å’æ¥­è¦ä»¶ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“")

    formatted_text = "\n".join(out_lines)

    if return_dict:
        # parsed: å„ã‚«ãƒ†ã‚´ãƒªã®å–å¾—å€¤ã€lack_dict: å„ã‚«ãƒ†ã‚´ãƒªã®ä¸è¶³
        return formatted_text, {"parsed": parsed, "lack": lack_dict}

    return formatted_text


# é–‹ç™ºç”¨ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
if __name__ == "__main__":
    import sys
    path = sys.argv[1] if len(sys.argv) > 1 else "æˆç¸¾.pdf"
    print(check_pdf(path))
